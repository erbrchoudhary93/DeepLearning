{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31bac9b8",
   "metadata": {},
   "source": [
    "# Install required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0212fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] [-e] <vcs project url> ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] [-e] <local project path> ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Usage:   \n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] [-e] <vcs project url> ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] [-e] <local project path> ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Usage:   \n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] [-e] <vcs project url> ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] [-e] <local project path> ...\n",
      "  /home/ram/Desktop/DeepLearning/env/bin/python -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install required packages for the project\n",
    "\n",
    "%pip install torch torchvision torchaudio -quit --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install -quit matplotlib\n",
    "%pip install -quit safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fddd5",
   "metadata": {},
   "source": [
    "##   import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31702f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701a69d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb8e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='.',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f25b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(\n",
    "    root='.',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a782120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f52e73",
   "metadata": {},
   "source": [
    "## Converting data in to batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c26f90ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 157\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e21c106",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train the model\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "# Evaluate the model\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return total_loss / len(test_loader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,in_dim,n_class):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.n_class = n_class\n",
    "        self.linear = nn.Linear(in_dim, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out=self.linear(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776e53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(28*28,10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "992185ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['linear.weight', 'linear.bias'])\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model.state_dict()\n",
    "print(model.state_dict().keys())\n",
    "print(model.state_dict()['linear.weight'].shape)\n",
    "print(model.state_dict()['linear.bias'].shape)\n",
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7bf64a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0039,  0.0246,  0.0163,  ...,  0.0170, -0.0328,  0.0249],\n",
      "        [ 0.0297,  0.0210, -0.0226,  ...,  0.0204,  0.0281,  0.0152],\n",
      "        [ 0.0291, -0.0096, -0.0228,  ...,  0.0060, -0.0263, -0.0275],\n",
      "        ...,\n",
      "        [-0.0101, -0.0120,  0.0347,  ...,  0.0341,  0.0138, -0.0268],\n",
      "        [-0.0073,  0.0138, -0.0247,  ..., -0.0211, -0.0249,  0.0287],\n",
      "        [-0.0243,  0.0280, -0.0356,  ...,  0.0003,  0.0271, -0.0198]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0019,  0.0347, -0.0093,  0.0172, -0.0102, -0.0055, -0.0233,  0.0163,\n",
      "        -0.0055, -0.0214], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d27ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# For CuDA support, check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de8ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# for MPS support (Apple Silicon Macs)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88cc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b0b6ad",
   "metadata": {},
   "source": [
    "# Building Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8c3cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Epoch [1/5], Step [100/938], Loss: 0.1266, Accuracy: 0.9261\n",
      "Epoch [1/5], Step [200/938], Loss: 0.3006, Accuracy: 0.9265\n",
      "Epoch [1/5], Step [300/938], Loss: 0.2388, Accuracy: 0.9244\n",
      "Epoch [1/5], Step [400/938], Loss: 0.1688, Accuracy: 0.9239\n",
      "Epoch [1/5], Step [500/938], Loss: 0.1805, Accuracy: 0.9243\n",
      "Epoch [1/5], Step [600/938], Loss: 0.0855, Accuracy: 0.9240\n",
      "Epoch [1/5], Step [700/938], Loss: 0.3547, Accuracy: 0.9234\n",
      "Epoch [1/5], Step [800/938], Loss: 0.2096, Accuracy: 0.9235\n",
      "Epoch [1/5], Step [900/938], Loss: 0.3291, Accuracy: 0.9231\n",
      "Epoch [1/5] completed in 26.54 seconds, Loss: 0.2755, Accuracy: 0.9233\n",
      "********************\n",
      "Epoch [2/5], Step [100/938], Loss: 0.2530, Accuracy: 0.9223\n",
      "Epoch [2/5], Step [200/938], Loss: 0.3298, Accuracy: 0.9241\n",
      "Epoch [2/5], Step [300/938], Loss: 0.2981, Accuracy: 0.9221\n",
      "Epoch [2/5], Step [400/938], Loss: 0.2728, Accuracy: 0.9223\n",
      "Epoch [2/5], Step [500/938], Loss: 0.1497, Accuracy: 0.9225\n",
      "Epoch [2/5], Step [600/938], Loss: 0.3133, Accuracy: 0.9232\n",
      "Epoch [2/5], Step [700/938], Loss: 0.2590, Accuracy: 0.9231\n",
      "Epoch [2/5], Step [800/938], Loss: 0.2438, Accuracy: 0.9228\n",
      "Epoch [2/5], Step [900/938], Loss: 0.2498, Accuracy: 0.9232\n",
      "Epoch [2/5] completed in 26.17 seconds, Loss: 0.2751, Accuracy: 0.9236\n",
      "********************\n",
      "Epoch [3/5], Step [100/938], Loss: 0.2967, Accuracy: 0.9195\n",
      "Epoch [3/5], Step [200/938], Loss: 0.1425, Accuracy: 0.9191\n",
      "Epoch [3/5], Step [300/938], Loss: 0.2391, Accuracy: 0.9211\n",
      "Epoch [3/5], Step [400/938], Loss: 0.4809, Accuracy: 0.9207\n",
      "Epoch [3/5], Step [500/938], Loss: 0.2240, Accuracy: 0.9208\n",
      "Epoch [3/5], Step [600/938], Loss: 0.5189, Accuracy: 0.9213\n",
      "Epoch [3/5], Step [700/938], Loss: 0.2046, Accuracy: 0.9219\n",
      "Epoch [3/5], Step [800/938], Loss: 0.1930, Accuracy: 0.9227\n",
      "Epoch [3/5], Step [900/938], Loss: 0.3412, Accuracy: 0.9230\n",
      "Epoch [3/5] completed in 24.86 seconds, Loss: 0.2737, Accuracy: 0.9233\n",
      "********************\n",
      "Epoch [4/5], Step [100/938], Loss: 0.1840, Accuracy: 0.9230\n",
      "Epoch [4/5], Step [200/938], Loss: 0.2288, Accuracy: 0.9236\n",
      "Epoch [4/5], Step [300/938], Loss: 0.4311, Accuracy: 0.9233\n",
      "Epoch [4/5], Step [400/938], Loss: 0.2774, Accuracy: 0.9239\n",
      "Epoch [4/5], Step [500/938], Loss: 0.3287, Accuracy: 0.9240\n",
      "Epoch [4/5], Step [600/938], Loss: 0.3771, Accuracy: 0.9249\n",
      "Epoch [4/5], Step [700/938], Loss: 0.2148, Accuracy: 0.9244\n",
      "Epoch [4/5], Step [800/938], Loss: 0.2707, Accuracy: 0.9241\n",
      "Epoch [4/5], Step [900/938], Loss: 0.3442, Accuracy: 0.9234\n",
      "Epoch [4/5] completed in 23.82 seconds, Loss: 0.2734, Accuracy: 0.9236\n",
      "********************\n",
      "Epoch [5/5], Step [100/938], Loss: 0.1802, Accuracy: 0.9270\n",
      "Epoch [5/5], Step [200/938], Loss: 0.1556, Accuracy: 0.9259\n",
      "Epoch [5/5], Step [300/938], Loss: 0.2799, Accuracy: 0.9248\n",
      "Epoch [5/5], Step [400/938], Loss: 0.1536, Accuracy: 0.9248\n",
      "Epoch [5/5], Step [500/938], Loss: 0.2528, Accuracy: 0.9242\n",
      "Epoch [5/5], Step [600/938], Loss: 0.2968, Accuracy: 0.9237\n",
      "Epoch [5/5], Step [700/938], Loss: 0.1756, Accuracy: 0.9240\n",
      "Epoch [5/5], Step [800/938], Loss: 0.3591, Accuracy: 0.9246\n",
      "Epoch [5/5], Step [900/938], Loss: 0.1550, Accuracy: 0.9246\n",
      "Epoch [5/5] completed in 23.91 seconds, Loss: 0.2720, Accuracy: 0.9246\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"*\"*20)\n",
    "    start_time = time.time()\n",
    "    running_loss=0\n",
    "    running_acc=0\n",
    "    model.train()\n",
    "    for i ,data in enumerate(train_loader,1):\n",
    "        images, labels = data\n",
    "        # Flatten the images\n",
    "        images = images.view(images.size(0), -1)  # Flatten the images\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # running_acc += (predicted == labels).sum().item()\n",
    "        running_acc += (predicted == labels).float().mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}, Accuracy: {running_acc / i:.4f}\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {end_time - start_time:.2f} seconds, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {running_acc / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ccb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d100ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Epoch [1/5], Step [100/938], Loss: 0.1936, Accuracy: 0.9258\n",
      "Epoch [1/5], Step [200/938], Loss: 0.1651, Accuracy: 0.9269\n",
      "Epoch [1/5], Step [300/938], Loss: 0.1411, Accuracy: 0.9254\n",
      "Epoch [1/5], Step [400/938], Loss: 0.4887, Accuracy: 0.9248\n",
      "Epoch [1/5], Step [500/938], Loss: 0.1467, Accuracy: 0.9245\n",
      "Epoch [1/5], Step [600/938], Loss: 0.1807, Accuracy: 0.9247\n",
      "Epoch [1/5], Step [700/938], Loss: 0.1508, Accuracy: 0.9251\n",
      "Epoch [1/5], Step [800/938], Loss: 0.5002, Accuracy: 0.9257\n",
      "Epoch [1/5], Step [900/938], Loss: 0.2957, Accuracy: 0.9263\n",
      "55575 60000\n",
      "Epoch [1/5] completed in 24.74 seconds, Loss: 0.2660, Accuracy: 0.9263\n",
      "********************\n",
      "Epoch [2/5], Step [100/938], Loss: 0.3516, Accuracy: 0.9272\n",
      "Epoch [2/5], Step [200/938], Loss: 0.3065, Accuracy: 0.9245\n",
      "Epoch [2/5], Step [300/938], Loss: 0.3444, Accuracy: 0.9258\n",
      "Epoch [2/5], Step [400/938], Loss: 0.2819, Accuracy: 0.9261\n",
      "Epoch [2/5], Step [500/938], Loss: 0.2135, Accuracy: 0.9261\n",
      "Epoch [2/5], Step [600/938], Loss: 0.1768, Accuracy: 0.9260\n",
      "Epoch [2/5], Step [700/938], Loss: 0.1107, Accuracy: 0.9271\n",
      "Epoch [2/5], Step [800/938], Loss: 0.2477, Accuracy: 0.9263\n",
      "Epoch [2/5], Step [900/938], Loss: 0.2906, Accuracy: 0.9263\n",
      "55571 60000\n",
      "Epoch [2/5] completed in 25.25 seconds, Loss: 0.2653, Accuracy: 0.9262\n",
      "********************\n",
      "Epoch [3/5], Step [100/938], Loss: 0.1366, Accuracy: 0.9253\n",
      "Epoch [3/5], Step [200/938], Loss: 0.2023, Accuracy: 0.9271\n",
      "Epoch [3/5], Step [300/938], Loss: 0.2015, Accuracy: 0.9255\n",
      "Epoch [3/5], Step [400/938], Loss: 0.2560, Accuracy: 0.9233\n",
      "Epoch [3/5], Step [500/938], Loss: 0.3829, Accuracy: 0.9239\n",
      "Epoch [3/5], Step [600/938], Loss: 0.1737, Accuracy: 0.9246\n",
      "Epoch [3/5], Step [700/938], Loss: 0.4746, Accuracy: 0.9240\n",
      "Epoch [3/5], Step [800/938], Loss: 0.3519, Accuracy: 0.9245\n",
      "Epoch [3/5], Step [900/938], Loss: 0.1985, Accuracy: 0.9250\n",
      "55513 60000\n",
      "Epoch [3/5] completed in 26.10 seconds, Loss: 0.2653, Accuracy: 0.9252\n",
      "********************\n",
      "Epoch [4/5], Step [100/938], Loss: 0.3072, Accuracy: 0.9269\n",
      "Epoch [4/5], Step [200/938], Loss: 0.5239, Accuracy: 0.9270\n",
      "Epoch [4/5], Step [300/938], Loss: 0.1529, Accuracy: 0.9265\n",
      "Epoch [4/5], Step [400/938], Loss: 0.4019, Accuracy: 0.9260\n",
      "Epoch [4/5], Step [500/938], Loss: 0.1702, Accuracy: 0.9264\n",
      "Epoch [4/5], Step [600/938], Loss: 0.1287, Accuracy: 0.9269\n",
      "Epoch [4/5], Step [700/938], Loss: 0.2441, Accuracy: 0.9265\n",
      "Epoch [4/5], Step [800/938], Loss: 0.3941, Accuracy: 0.9262\n",
      "Epoch [4/5], Step [900/938], Loss: 0.3715, Accuracy: 0.9265\n",
      "55593 60000\n",
      "Epoch [4/5] completed in 26.19 seconds, Loss: 0.2650, Accuracy: 0.9265\n",
      "********************\n",
      "Epoch [5/5], Step [100/938], Loss: 0.4243, Accuracy: 0.9314\n",
      "Epoch [5/5], Step [200/938], Loss: 0.2738, Accuracy: 0.9292\n",
      "Epoch [5/5], Step [300/938], Loss: 0.2234, Accuracy: 0.9279\n",
      "Epoch [5/5], Step [400/938], Loss: 0.2632, Accuracy: 0.9271\n",
      "Epoch [5/5], Step [500/938], Loss: 0.2072, Accuracy: 0.9277\n",
      "Epoch [5/5], Step [600/938], Loss: 0.3390, Accuracy: 0.9276\n",
      "Epoch [5/5], Step [700/938], Loss: 0.1315, Accuracy: 0.9275\n",
      "Epoch [5/5], Step [800/938], Loss: 0.2215, Accuracy: 0.9272\n",
      "Epoch [5/5], Step [900/938], Loss: 0.3694, Accuracy: 0.9268\n",
      "55592 60000\n",
      "Epoch [5/5] completed in 28.63 seconds, Loss: 0.2644, Accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"*\" * 20)\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        images, labels = data\n",
    "        images = images.view(images.size(0), -1)  # Flatten the images\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        # print(outputs, labels.data,outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        # print(total_correct, total_samples)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(train_loader)}], \"f\"Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    # print(f\"Outputs : {outputs}\")\n",
    "    # print(f\"Outputs Data : {outputs.data}\")\n",
    "    print(total_correct, total_samples)\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = total_correct / total_samples\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {end_time - start_time:.2f} seconds, \"f\"Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aeeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the model\n",
    "# model.eval()\n",
    "# eval_loss=0\n",
    "# eval_acc=0\n",
    "# with torch.no_grad():\n",
    "#     predicted=model(x_train)\n",
    "\n",
    "# # Make predictions\n",
    "# print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a5eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d616c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb1cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbfead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f4707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9888adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77447bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, criterion, optimizer, and device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "# Load the model\n",
    "model = SimpleCNN().to(device)\n",
    "model.load_state_dict(torch.load('mnist_cnn.pth', map_location=device))\n",
    "# Evaluate the loaded model\n",
    "test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "print(f'Loaded Model - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "def visualize_predictions(model, test_loader, device):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(15, 3))\n",
    "    for i in range(10):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Pred: {predicted[i].item()}\\nTrue: {labels[i].item()}')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "visualize_predictions(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in safetensors format\n",
    "import safetensors.torch\n",
    "safetensors.save_model(model, 'mnist_cnn.safetensors')\n",
    "# Load the model from safetensors format\n",
    "model = safetensors.load_model(SimpleCNN(), 'mnist_cnn.safetensors', map_location=device)\n",
    "# Evaluate the loaded model from safetensors\n",
    "test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "print(f'Loaded Safetensors Model - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "# Clean up      \n",
    "import os  \n",
    "os.remove('mnist_cnn.pth')\n",
    "os.remove('mnist_cnn.safetensors')\n",
    "print(\"Cleaned up model files.\")\n",
    "# End of the script\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Script executed successfully.\")\n",
    "    sys.exit(0)\n",
    "# End of the script\n",
    "# End of the script "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
